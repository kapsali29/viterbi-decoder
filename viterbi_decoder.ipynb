{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load required Python libraries\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "from nltk import sent_tokenize\n",
    "from random import randint\n",
    "import math\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from random import sample\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Φόρτωση των αρχείων του ευρωπαικού κοινοβουλίου\n",
    "# Θέτουμε ως train set το 0.05% των συνολικών κειμένων με σκοπό τον προσδιορισμό \n",
    "# των unigrams και bigrams\n",
    "files = os.listdir(\"C:/Users/User/Desktop/Text Engineering/en\")\n",
    "train_set = files[0:round(len(files)*0.05)]\n",
    "test_set = files[round(len(files)*0.05):round(len(files)*0.05)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Φόρτωση των κειμένων των αρχείων σε μια list of lists, η πρώτη λίστα δηλαδή περιέχει \n",
    "#το κείμενο του πρώτου αρχείου\n",
    "txt = []\n",
    "for fname in train_set:\n",
    "    with open('C:/Users/User/Desktop/Text Engineering/en/'+fname, 'r', encoding='utf8') as outfile:\n",
    "        txt.append(outfile.read().replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23355017"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Καθαρισμός δεδομένων\n",
    "#Εισάγουμε το q0->Start και το qf->end σε κάθε κείμενο\n",
    "ntxt = []\n",
    "for data in txt:\n",
    "    data = re.sub('<[^>]*>', '', data)\n",
    "    data = data.lower()\n",
    "    data = 'q0' + ' ' +data+ ' '+ 'qf'\n",
    "    ntxt.append(data)\n",
    "txt = []\n",
    "data = ''.join(ntxt)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(data)\n",
    "corpus_size = len(tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62467"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Κάνοντας χρήση της συνάρτησης Counter της βιβλιοθηκης collections μετράμε τις συχνότητες εμφάνισης για κάθε λέξη\n",
    "# στο Corpus\n",
    "ntxt = []\n",
    "count_tokens = dict(Counter(tokens))\n",
    "len(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Αφαιρούμε από το λεξικό των μονογραμμάτων τις λέξεις που έχουν συχνότητα εμφάνισης μικρότερη από 10\n",
    "# στην συνέχεια βρίσκουμε τις rare λέξεις (συχνότητα <=10)\n",
    "unigrams = dict((k, v) for k, v in count_tokens.items() if v>10)\n",
    "vocab_size = len(unigrams)\n",
    "rare = dict((k, v) for k, v in count_tokens.items() if v<=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Στα tokens, δηλαδή τις λέξεις, όποια λέξη άνήκει στις rare (συχνότητα <=10), την αντικαθιστούμε με rare \n",
    "for i in range(len(tokens)):\n",
    "    if tokens[i] in rare.keys():\n",
    "        tokens[i] = '*rare*'\n",
    "count_tokens = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23355016"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Δημιουργία δι-γραμμάτων με την χρήση της NLTK\n",
    "bigrams = [ gram for gram in ngrams(tokens, 2)]\n",
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##εφαρμόζουμε την συνάρτηση Counter στα διγράμματα για να βρούμε τα μοναδικά διγράμματα\n",
    "#καθώς και τις συχνότητες εμφάνισης τους\n",
    "count_bigrams = dict(Counter(bigrams))\n",
    "len(count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16174"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# βρίσκουμε τα διγράμματα που περιέχουν την λέξη rare\n",
    "rare_bigrams = [k for k in count_bigrams.keys() if '*rare*' in k]\n",
    "len(rare_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Αφαιρούμε από τα μοναδικά διγράμματα τα διγράμματα που περιέχουν την λέξη rare\n",
    "for item in rare_bigrams:\n",
    "    count_bigrams.pop(item, None)\n",
    "len(count_bigrams)\n",
    "bigrams = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# H παρακάτω συνάρτηση υπολογίζει την πιθανότητα διγραμμάτων δηλαδή p(wi|wi-1)\n",
    "# κάνοντας χρήση του Laplace Smoothing\n",
    "def get_bigram_prob(key):\n",
    "    if key[0] in unigrams.keys():\n",
    "        if key not in count_bigrams.keys():\n",
    "            prob = (0+1)/(vocab_size+unigrams[key[0]])\n",
    "        else:\n",
    "            prob = (count_bigrams[key]+1)/(vocab_size+unigrams[key[0]])\n",
    "    else:\n",
    "        if len(key) == 2:\n",
    "            if key[1] in unigrams.keys():\n",
    "                prob = 0.4*(unigrams[key[1]]/sum(unigrams.values()))\n",
    "            else:\n",
    "                prob = 0.4/sum(unigrams.values())\n",
    "        else:\n",
    "            prob = 0.4/sum(unigrams.values())\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Διάβασμα του τεστ αρχείου ανά γραμμές\n",
    "sentences = []\n",
    "for fname in test_set:\n",
    "    with open('C:/Users/User/Desktop/Text Engineering/en/'+fname, 'r', encoding='utf8') as f:\n",
    "        sentences += re.findall(r\".*?[\\.\\!\\?]+\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# τυχαία επιλογή πρότασης από το τεστ κείμενο\n",
    "selected = random.choice(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr President, the remarks by my colleague, Mr Manders, did not come over very clearly via the interpretation.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#καθαρισμός της πρότασης και σπάσιμο στα tokens της\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sel_tokens = tokenizer.tokenize(selected.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'president',\n",
       " 'the',\n",
       " 'remarks',\n",
       " 'by',\n",
       " 'my',\n",
       " 'colleague',\n",
       " 'mr',\n",
       " 'manders',\n",
       " 'did',\n",
       " 'not',\n",
       " 'come',\n",
       " 'over',\n",
       " 'very',\n",
       " 'clearly',\n",
       " 'via',\n",
       " 'the',\n",
       " 'interpretation']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Τυχαία επιλογή των tokens στα οποία θα εισαχθεί θόρυβος. (μπορεί να είναι 1 έως όλες οι λέξεις της πρότασης) \n",
    "#Σε κάθε μία από τις επιλεγμένες λέξεις αντικαθιστούμε πάλι τυχαία ορισμένα ή και όλα τα \n",
    "#γράμματα της λέξης με κάποιο από τα υπόλοιπα γράμματα της αλφαβήτου ή και το κενό. \n",
    "def mis_spelling(sel_tokens):\n",
    "    miss_words = int(input('Please set number of mis-spelled words: '))\n",
    "    noise = []\n",
    "    chosen_words = random.sample(range(0, len(sel_tokens)-1), 3)\n",
    "    for i in range(0,len(sel_tokens)):\n",
    "        if i in chosen_words:\n",
    "            word = sel_tokens[i]\n",
    "            letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "            num_chars = randint(0,len(word)-1)\n",
    "            inds = random.sample(range(0,len(word)-1),num_chars)\n",
    "            let = random.sample(letters,num_chars)\n",
    "            for i in range(0,num_chars):\n",
    "                word = word[0:inds[i]]+let[i]+word[inds[i]+1:]\n",
    "            noise.append(word)\n",
    "        else:\n",
    "            noise.append(sel_tokens[i])\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please set number of mis-spelled words: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'president',\n",
       " 'the',\n",
       " 'remnrks',\n",
       " 'by',\n",
       " 'my',\n",
       " 'colleague',\n",
       " 'mr',\n",
       " 'manders',\n",
       " 'did',\n",
       " 'not',\n",
       " 'come',\n",
       " 'over',\n",
       " 'very',\n",
       " 'clearly',\n",
       " 'vma',\n",
       " 'the',\n",
       " 'interpretation']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Εκτύπωση των tokens της πρότασης εφόσον έχει εισαχθεί θόρυβος\n",
    "noise = mis_spelling(sel_tokens)\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# κάνοντας χρήση της συνάρτησης edit distance της βιβλιοθήκης NLTK\n",
    "# και υπολογιζουμε για καθε λεξη τις 2 πιο κοντινές της\n",
    "# θεωρούμε ως wi τις λέξεις στις οποίες έχει εισαχθεί θόρυβος\n",
    "# θεωρούμε ως ti τις λέξεις που έρχονται ως αποτέλεσμα από την edit distance\n",
    "w_in = noise\n",
    "correct = dict()\n",
    "for word in w_in:\n",
    "    pos_dist = dict()\n",
    "    for key in unigrams.keys():\n",
    "        pos_dist[key] = edit_distance(word,key)\n",
    "    correct[word] = sorted(pos_dist.items(), key=operator.itemgetter(1)) [0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'by': [('by', 0), ('bay', 1)],\n",
       " 'clearly': [('clearly', 0), ('cheaply', 2)],\n",
       " 'colleague': [('colleague', 0), ('colleagues', 1)],\n",
       " 'come': [('come', 0), ('home', 1)],\n",
       " 'did': [('did', 0), ('dip', 1)],\n",
       " 'interpretation': [('interpretation', 0), ('interpretations', 1)],\n",
       " 'manders': [('manders', 0), ('anders', 1)],\n",
       " 'mr': [('mr', 0), ('or', 1)],\n",
       " 'my': [('my', 0), ('m3', 1)],\n",
       " 'not': [('not', 0), ('nut', 1)],\n",
       " 'over': [('over', 0), ('mover', 1)],\n",
       " 'president': [('president', 0), ('resident', 1)],\n",
       " 'remnrks': [('remarks', 1), ('remark', 2)],\n",
       " 'the': [('the', 0), ('tse', 1)],\n",
       " 'very': [('very', 0), ('vary', 1)],\n",
       " 'vma': [('vms', 1), ('via', 1)]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Πιο συγκεκριμένα για κάθε λέξη επιστρέφονται 2 λέξεις όπως και παρατηρούμε στο παρακάτω λεξικό\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## viterbi decoding\n",
    "## το παρακάτω απόσπασμα κώδικα υλοποιεί τον αλγόριθμο viterbi\n",
    "viterbi = []\n",
    "t_prev = []\n",
    "for i in range(0,len(w_in)):\n",
    "    temp = []\n",
    "    temp1 = []\n",
    "    if i == 0:\n",
    "        #V1 (t1) = P(t1|Start)P(w1|t1) \n",
    "        correct_w = correct[w_in[0]]\n",
    "        for item in correct_w:\n",
    "            temp.append( (item[0],-item[1] + np.log2(get_bigram_prob((item[0],'q0')))))\n",
    "            temp1.append('q0')\n",
    "        viterbi.append(temp)\n",
    "        t_prev.append(temp1)\n",
    "    else:\n",
    "        #P(wk|tk)max_(tk-1){P(tk|tk-1)Vk-1(tk-1)}\n",
    "        correct_w = correct[w_in[i]]\n",
    "        for item in correct_w:\n",
    "            find_max = []\n",
    "            for tiprev in viterbi[i-1]:\n",
    "                num = -item[1] + np.log2(get_bigram_prob((item[0],tiprev[0]))) + tiprev[1]\n",
    "                find_max.append((tiprev[0],num))\n",
    "            tt = max(find_max,key=itemgetter(1))\n",
    "            temp1.append(tt[0])\n",
    "            temp.append((item[0],tt[1]))\n",
    "        t_prev.append(temp1)\n",
    "        viterbi.append(temp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('mr', -16.865999016160831), ('or', -17.178645401254993)],\n",
       " [('president', -22.150333607045219), ('resident', -29.990153894444223)],\n",
       " [('the', -30.446455676388382), ('tse', -37.535184796429967)],\n",
       " [('remarks', -40.271668894148391), ('remark', -44.047098711401723)],\n",
       " [('by', -56.434483071372526), ('bay', -55.669410366497203)],\n",
       " [('my', -71.566901343265357), ('m3', -69.81622878590909)],\n",
       " [('colleague', -84.336233527547691), ('colleagues', -84.013123104685036)],\n",
       " [('mr', -100.87912212084586), ('or', -99.606806005218871)],\n",
       " [('manders', -113.99037530868316), ('anders', -114.98692881445277)],\n",
       " [('did', -128.84241707507553), ('dip', -129.3700921061768)],\n",
       " [('not', -144.71763046696759), ('nut', -144.22490601152057)],\n",
       " [('come', -155.74907896633462), ('home', -158.3299806617415)],\n",
       " [('over', -170.94767747781967), ('mover', -171.12913411487952)],\n",
       " [('very', -186.93265214996919), ('vary', -185.34602036546556)],\n",
       " [('clearly', -197.56162522756591), ('cheaply', -201.73053432686419)],\n",
       " [('vms', -212.94140970161828), ('via', -213.03234764387761)],\n",
       " [('the', -231.48985357333277), ('tse', -228.32626089100302)],\n",
       " [('interpretation', -242.02233937754147),\n",
       "  ('interpretations', -243.71730304766433)]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Το αποτέλεσμα του παραπάνω κώδικα αποθηκεύεται σε μια list of tuples\n",
    "# παρατηρούμε ότι για κάθε κοντινή λέξη (ti) μιας λέξης, ΄στην οποία έχει εισαχθεί θόρυβος, wi υπολογίζεται μια πιθανότητα\n",
    "viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'president',\n",
       " 'the',\n",
       " 'remarks',\n",
       " 'bay',\n",
       " 'm3',\n",
       " 'colleagues',\n",
       " 'or',\n",
       " 'manders',\n",
       " 'did',\n",
       " 'not',\n",
       " 'come',\n",
       " 'over',\n",
       " 'very',\n",
       " 'clearly',\n",
       " 'via',\n",
       " 'the',\n",
       " 'interpretation']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#υπολογισμός της μέγιστης πιθανότητας για την τελευταία λέξη w\n",
    "# και εκτελώντας προς τα πίσω τον αλγόριθμο εντοπίζουμε το πιο πιθανό μονοπάτι\n",
    "# το οποίο και εκτυπώνεται\n",
    "max_el = max(viterbi[len(t_prev)-1],key=itemgetter(1))\n",
    "max_index = viterbi[len(t_prev)-1].index(max_el)\n",
    "path = []\n",
    "path.append(max_el[0])\n",
    "for j in range(0,len(t_prev)):\n",
    "        path.append(t_prev[len(t_prev)-1-j][0])\n",
    "most_probable_path = path[::-1][1:]\n",
    "most_probable_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between correct sentence and most propable sentence 0.0695906432748538\n",
      "Correct predicted words:  14\n",
      "Wrong predicted words:  4\n"
     ]
    }
   ],
   "source": [
    "## calculate average distance (using edit_distance NLTK package)\n",
    "## έχοντας πλέον την πιο πιθανή αλληλουχία λέξεων που προέκυψαν από την εκτέλεση του αλγορίθμου\n",
    "# καθώς και την αρχική πρόταση πριν εισαχθεί σε αυτή ο θόρυβος\n",
    "# υπολογίζουμε τις λέξεις που διόρθωσε σωστά ο viterbi context-sensitive corrector\n",
    "# υπολογίζουμε τις λέξεις που προέβλεωε λάθος\n",
    "# καθώς και την μέση oμοιότητα μεταξύ των λέξεων της μη-αλλοιωμένης πρότασης με τις λέξεις της πιο πιθανής αλλοιλουχίας\n",
    "# που εντοπίσαμε\n",
    "total = 0\n",
    "num_of_correct_predicted_words = 0\n",
    "for i in range(0,len(sel_tokens)):\n",
    "    a = sel_tokens[i]\n",
    "    b = most_probable_path[i]\n",
    "    seq = difflib.SequenceMatcher(a=a.lower(), b=b.lower())\n",
    "    #total += edit_distance(sel_tokens[i],most_probable_path[i])\n",
    "    total += (1-seq.ratio())\n",
    "    if seq.ratio() == 1:\n",
    "        num_of_correct_predicted_words += 1\n",
    "wrong_words = len(sel_tokens) - num_of_correct_predicted_words\n",
    "avg_distance = total/len(sel_tokens)\n",
    "print('Average difference between correct sentence and most propable sentence', avg_distance)\n",
    "print('Correct predicted words: ', num_of_correct_predicted_words)\n",
    "print('Wrong predicted words: ', wrong_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['or',\n",
       " 'resident',\n",
       " 'tse',\n",
       " 'remark',\n",
       " 'bay',\n",
       " 'm3',\n",
       " 'colleagues',\n",
       " 'or',\n",
       " 'anders',\n",
       " 'dip',\n",
       " 'nut',\n",
       " 'home',\n",
       " 'mover',\n",
       " 'vary',\n",
       " 'cheaply',\n",
       " 'via',\n",
       " 'tse',\n",
       " 'interpretations']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## baseline\n",
    "## εφαρμόζουμε στην πρόταση με θόρυβο την συνάρτηση edit distance\n",
    "## και στην συνέχεια αποθηκεύουμε σε λίστα\n",
    "base = []\n",
    "for item in noise:\n",
    "    base.append(correct[item][1][0])\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between correct sentence and most propable sentence 0.23499681949915038\n",
      "Correct predicted words:  1\n",
      "Wrong predicted words:  17\n"
     ]
    }
   ],
   "source": [
    "## συγκρίνουμε το αποτέλεσμα της edit distance πάνω στην αλλοιωμένη πρόταση με την αρχική πρόταση.\n",
    "total1 = 0\n",
    "num_of_correct = 0\n",
    "wrong = 0\n",
    "for i in range(0,len(sel_tokens)):\n",
    "    a = sel_tokens[i]\n",
    "    b = base[i]\n",
    "    seq = difflib.SequenceMatcher(a=a.lower(), b=b.lower())\n",
    "    total1 += (1-seq.ratio())\n",
    "    if seq.ratio() == 1:\n",
    "        num_of_correct +=1\n",
    "wrong = len(sel_tokens) - num_of_correct\n",
    "avg = total1/len(sel_tokens)\n",
    "print('Average difference between correct sentence and most propable sentence', avg)\n",
    "print('Correct predicted words: ', num_of_correct)\n",
    "print('Wrong predicted words: ', wrong)          "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
